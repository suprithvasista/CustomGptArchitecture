Created a custom gpt architecture and trained a Language model using open source book.
This repo consists of:
  preprocessing code
  architecure code
  train data sets
  vovabulary

The train model loss achived in the short time is 0.5 --> 60 %
and the val model loss is 0.59 --> 55 %

Will try to train this model more on specific use cases documents related to user doc's to make a rag system out of this model in upcoming days.
