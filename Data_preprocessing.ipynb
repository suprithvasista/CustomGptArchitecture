{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN1d7jn/l0IWtm077wiIrex"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuNPp0gBSsgG","executionInfo":{"status":"ok","timestamp":1735727879372,"user_tz":-330,"elapsed":406,"user":{"displayName":"suprith M","userId":"00511320900459597163"}},"outputId":"646e3dcb-de3c-4de4-8c4b-fcf47cf65918"},"outputs":[{"output_type":"stream","name":"stdout","text":["['output_train.txt', 'output_val.txt']\n","2\n","1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 123.71it/s]\n","100%|██████████| 1/1 [00:00<00:00, 264.74it/s]\n"]}],"source":["import os\n","import random\n","import concurrent.futures\n","from tqdm import tqdm\n","\n","def process_file(args):\n","    directory, filename, output_file, vocab = args\n","    file_path = os.path.join(directory, filename)\n","    try:\n","        with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n","            text = infile.read()\n","    except Exception as e:\n","        print(f\"Skipping file {file_path} due to error: {e}\")\n","        return set()  # Return an empty set if file cannot be read\n","\n","    with open(output_file, \"a\", encoding=\"utf-8\") as outfile:\n","        outfile.write(text)\n","\n","    characters = set(text)\n","    return characters\n","\n","def txt_files_in_dir(directory):\n","    return [filename for filename in os.listdir(directory) if filename.endswith(\".txt\") and os.path.isfile(os.path.join(directory, filename))]\n","\n","def process_files_in_parallel(files, folder_path, output_file):\n","    vocab = set()\n","    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n","        args = [(folder_path, filename, output_file, vocab) for filename in files]\n","        for characters in tqdm(executor.map(process_file, args), total=len(files)):\n","            vocab.update(characters)\n","    return vocab\n","\n","folder_path = \"/content/TXT_FILES/\"\n","output_file_train = \"output_train.txt\"\n","output_file_val = \"output_val.txt\"\n","vocab_file = \"vocab.txt\"\n","\n","files = txt_files_in_dir(folder_path)\n","print(files)\n","total_files = len(files)\n","print(total_files)\n","\n","split_index = int(total_files * 0.9)  # 90% for training\n","print(split_index)\n","files_train = files[:split_index]\n","files_val = files[split_index:]\n","\n","# Sampling a hundredth of the files for each split\n","sample_rate = 0.01\n","files_train_sampled = random.sample(files_train, max(1, int(len(files_train) * sample_rate)))\n","files_val_sampled = random.sample(files_val, max(1, int(len(files_val) * sample_rate)))\n","\n","# Ensure output files are empty before appending\n","open(output_file_train, 'w').close()\n","open(output_file_val, 'w').close()\n","\n","# Process the sampled training files\n","vocab_train = process_files_in_parallel(files_train_sampled, folder_path, output_file_train)\n","\n","# Process the sampled validation files\n","vocab_val = process_files_in_parallel(files_val_sampled, folder_path, output_file_val)\n","\n","# Combine vocabularies (if needed) and write to vocab.txt\n","vocab = vocab_train.union(vocab_val)\n","with open(vocab_file, \"w\", encoding=\"utf-8\") as vfile:\n","    for char in sorted(vocab):\n","        vfile.write(char + '\\n')\n"]},{"cell_type":"code","source":["!wget -O dataset.txt https://raw.githubusercontent.com/Infatoshi/fcc-intro-to-llms/refs/heads/main/wizard_of_oz.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HChck3DQSzvK","executionInfo":{"status":"ok","timestamp":1735726119119,"user_tz":-330,"elapsed":625,"user":{"displayName":"suprith M","userId":"00511320900459597163"}},"outputId":"c8fcbfc8-ac47-4e1c-aa6a-3228f69ae540"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-01-01 10:08:38--  https://raw.githubusercontent.com/Infatoshi/fcc-intro-to-llms/refs/heads/main/wizard_of_oz.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 237733 (232K) [text/plain]\n","Saving to: ‘dataset.txt’\n","\n","\rdataset.txt           0%[                    ]       0  --.-KB/s               \rdataset.txt         100%[===================>] 232.16K  --.-KB/s    in 0.02s   \n","\n","2025-01-01 10:08:38 (10.2 MB/s) - ‘dataset.txt’ saved [237733/237733]\n","\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Input file path\n","file_path = \"/content/Data/dataset.txt\"\n","\n","# Output file paths\n","output_file_train = \"output_train.txt\"\n","output_file_val = \"output_val.txt\"\n","\n","# Read the content of the file\n","with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n","    text = infile.read()\n","\n","# Calculate split index (90% for training)\n","split_index = int(len(text) * 0.9)\n","\n","# Split the text into training and evaluation parts\n","train_text = text[:split_index]  # First 90%\n","val_text = text[split_index:]    # Last 10%\n","\n","# Write the training data to a file\n","with open(output_file_train, \"w\", encoding=\"utf-8\") as train_file:\n","    train_file.write(train_text)\n","\n","# Write the evaluation data to a file\n","with open(output_file_val, \"w\", encoding=\"utf-8\") as val_file:\n","    val_file.write(val_text)\n","\n","# Print status\n","print(f\"Training data saved to {output_file_train}, size: {len(train_text)} characters\")\n","print(f\"Validation data saved to {output_file_val}, size: {len(val_text)} characters\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUaHYridZNyK","executionInfo":{"status":"ok","timestamp":1735727779969,"user_tz":-330,"elapsed":422,"user":{"displayName":"suprith M","userId":"00511320900459597163"}},"outputId":"c6e01a14-87d9-4a3f-f40b-51b6353aaf97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data saved to output_train.txt, size: 209078 characters\n","Validation data saved to output_val.txt, size: 23231 characters\n"]}]}]}